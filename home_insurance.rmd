```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, include = FALSE}
data <- read.csv("./data/home_insurance.csv")
```

##Removing Columns from the original dataset:

```{r, include = FALSE}
original_dataset <- read.csv("./data/home_insurance.csv")

#Identify the columns to remove
columns_to_remove <- c("QUOTE_DATE", "COVER_START", "P1_PT_EMP_STATUS", "CLERICAL", "AD_BUILDINGS", "AD_CONTENTS", 
"AD_CONTENTS", "RISK_RATED_AREA_C", "SUM_INSURED_CONTENTS", "CONTENTS_COVER", "P1_POLICY_REFUSED", "LISTED", "OWNERSHIP_TYPE", "PAYING_GUESTS", "PROP_TYPE", "CAMPAIGN_DESC", "PAYMENT_METHOD", "PAYMENT_FREQUENCY", "LEGAL_ADDON_PRE_REN", "LEGAL_ADDON_POST_REN", "HOME_EM_ADDON_PRE_REN", "HOME_EM_ADDON_POST_REN", "KEYCARE_ADDON_PRE_REN", "KEYCARE_ADDON_POST_REN", "HP1_ADDON_PRE_REN", "HP1_ADDON_POST_REN", "HP2_ADDON_PRE_REN", "HP2_ADDON_POST_REN", "HP3_ADDON_PRE_REN", "HP3_ADDON_POST_REN", "MTA_FLAG", "MTA_FAP", "MTA_APRP", "MTA_DATE",   "PAYING_GUESTS")

#Remove the specified columns
dataset <- original_dataset[, !(names(original_dataset) %in% columns_to_remove)]

# Step 4: Save the updated dataset to a new file
# write.csv(dataset, "./data/updated_data.csv", row.names = FALSE)
```

##Creates dataset_clean by removing rows with missing values from the original dataset.
```{r, include = FALSE}
dataset_clean <- dataset[complete.cases(dataset),]
write.csv(dataset_clean, "./data/clean_data.csv", row.names = FALSE)
```

##Read clean dataset.
```{r, include = FALSE}
dataset_clean <- read.csv("./data/clean_data.csv")
unique(dataset_clean$P1_DOB)
```

## convert the Date of birth column to Year of birth.
```{r, include = FALSE}
#Change format of DOB
# Load the lubridate package
library(lubridate)

# Convert the date column to a Date object
dataset_clean$P1_DOB <- dmy(dataset_clean$P1_DOB)  # Assumes day-month-year format

unique(dataset_clean$P1_DOB)

# Extract the year from the date column
dataset_clean$year <- year(dataset_clean$P1_DOB)

# Print the data frame with the extracted year
unique(dataset_clean$year)
```

##Reanming Columns
```{r, include = FALSE}
# Define the new column names
new_column_names <- c(
  "Claim_3_Years", "Employment_Status", "Business_Use", "Risk_Rated_Area_B",
  "Sum_Insured_Buildings", "NCD_Granted_Years_B", "NCD_Granted_Years_C",
  "Buildings_Cover", "Spec_Sum_Insured", "Spec_Item_Premium", "Unspec_HRP_Premium",
  "Date_of_Birth", "Marital_Status", "Sex", "Approved_Alarm", "Approved_Locks",
  "Bedrooms", "Roof_Construction", "Wall_Construction", "Flood_Risk",
  "Max_Days_Unoccupied", "Neighborhood_Watch", "Occupation_Status", "Security_Installed",
  "Security_Discount_Required", "Subsidence_Risk", "Year_Built", "Garden_Addon_Pre_Renovation",
  "Garden_Addon_Post_Renovation", "Last_Annual_Premium_Gross", "Policy_Status",
  "Record_ID", "Police_Station", "Year_of_Birth"
)

# Rename the columns
colnames(dataset_clean) <- new_column_names

# Check the updated column names
names(dataset_clean)

```

##Add age for each client
```{r, include = FALSE}
# Calculate the age for each client as of 2023
current_year <- 2007
dataset_clean$Age <- current_year - dataset_clean$Year_of_Birth

# Remove the "Year_of_Birth" column
dataset_clean <- subset(dataset_clean, select = -c(Year_of_Birth))

# check the updated dataset
head(dataset_clean)  # View the first few rows to verify the changes.

```

##Define Range of ages
```{r, include = FALSE}
# Print the sorted numbers
print(sort(unique(dataset_clean$Age)))
```

```{r, include = FALSE}
# Add the AVGsalary column based on the year ranges
dataset_clean$AVGsalary <- ifelse(
  dataset_clean$year >= ranges[1] & dataset_clean$year <= ranges[2], AVGsalary_values[1],
  ifelse(
    dataset_clean$year > ranges[2] & dataset_clean$year <= ranges[3], AVGsalary_values[2],
    ifelse(
      dataset_clean$year > ranges[3] & dataset_clean$year <= ranges[4], AVGsalary_values[3],
      ifelse(
        dataset_clean$year > ranges[4] & dataset_clean$year <= ranges[5], AVGsalary_values[4],
        ifelse(
          dataset_clean$year > ranges[5] & dataset_clean$year <= ranges[6], AVGsalary_values[5],
          ifelse(
            dataset_clean$year > ranges[6] & dataset_clean$year <= ranges[7], AVGsalary_values[6],
            ifelse(
              dataset_clean$year > ranges[7] & dataset_clean$year <= ranges[8], AVGsalary_values[7],
              ifelse(
                dataset_clean$year > ranges[8] & dataset_clean$year <= ranges[9], AVGsalary_values[8],
                ifelse(
                  dataset_clean$year > ranges[9] & dataset_clean$year <= ranges[10], AVGsalary_values[9],
                  ifelse(
                    dataset_clean$year > ranges[10] & dataset_clean$year <= ranges[11], AVGsalary_values[10],
                    ifelse(
                      dataset_clean$year > ranges[11] & dataset_clean$year <= ranges[12], AVGsalary_values[11],
                      ifelse(
                        dataset_clean$year > ranges[12] & dataset_clean$year <= ranges[13], AVGsalary_values[12],
                        ifelse(
                          dataset_clean$year > ranges[13] & dataset_clean$year <= ranges[14], AVGsalary_values[13],
                          ifelse(
                            dataset_clean$year > ranges[14] & dataset_clean$year <= ranges[15], AVGsalary_values[14],
                            ifelse(
                              dataset_clean$year > ranges[15] & dataset_clean$year <= ranges[16], AVGsalary_values[15],
                              ifelse(
                                dataset_clean$year > ranges[16] & dataset_clean$year <= ranges[17], AVGsalary_values[16],
                                ifelse(
                                  dataset_clean$year > ranges[17] & dataset_clean$year <= ranges[18], AVGsalary_values[17],
                                  ifelse(
                                    dataset_clean$year > ranges[18] & dataset_clean$year <= ranges[19], AVGsalary_values[18],
                                    ifelse(
                                      dataset_clean$year > ranges[19] & dataset_clean$year <= ranges[20], AVGsalary_values[19],
                                      ifelse(
                                        dataset_clean$year > ranges[20] & dataset_clean$year <= ranges[21], AVGsalary_values[20],
                                        NA
                                      )
                                    )
                                  )
                                )
                              )
                            )
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
          )
        )
      )
    )
  )
)

# Print the modified dataset
print(dataset_clean$AVGsalary)

```

```{r, include = FALSE}
final_dataset <- dataset_clean[, !(colnames(dataset_clean) %in% "P1_DOB")]
final_dataset <- dataset_clean[, !(colnames(dataset_clean) %in% "Police")]
write.csv(final_dataset, "./data/final_dataset.csv", row.names = FALSE)
```

```{r, include = FALSE}
final_dataset <- read.csv("./data/final_dataset.csv")
```

```{r, include = FALSE}
# Specify the column names that need to be changed
columns_to_change <- c("CLAIM3YEARS", "BUS_USE", "BUILDINGS_COVER", "APPR_LOCKS", "APPR_ALARM", "FLOODING", "NEIGH_WATCH", "SAFE_INSTALLED", "SEC_DISC_REQ", "SUBSIDENCE", "GARDEN_ADDON_PRE_REN", "GARDEN_ADDON_POST_REN")  

#  replace 'Y' with 1 and 'N' with 0
for (col in columns_to_change) {
  final_dataset[, col] <- ifelse(final_dataset[, col] == 'Y', 1, 0)
}
final_dataset$P1_SEX <- ifelse(final_dataset$P1_SEX == 'M', 0, 1)
```

```{r, include = FALSE}
# Assuming you're using the dplyr library
library(dplyr)

# Remove the 'p1DOB' column from the 'final_dataset' dataframe
final_dataset <- final_dataset %>% select(-'P1_DOB')

final_dataset <- final_dataset[!(final_dataset$P1_EMP_STATUS %in% c("A", "C", "I", "N")), ]

```

```{r, include = FALSE}
 unique(final_dataset$P1_EMP_STATUS)
```

```{r, include = FALSE}
 library(dplyr)
library(tidyr)

final_dataset <- final_dataset %>%
  mutate(P1_EMP_STATUS = factor(P1_EMP_STATUS, levels = c("R", "E", "S", "H", "U", "F", "V"))) %>%
  mutate(P1_EMP_STATUS = as.character(P1_EMP_STATUS)) %>%
  mutate_all(~ifelse(is.na(.), "Unknown", .)) # Replace any NA values with "Unknown"

final_dataset <- final_dataset %>%
  mutate(R_emp_status = as.integer(P1_EMP_STATUS == "R"),
         E_emp_status = as.integer(P1_EMP_STATUS == "E"),
         S_emp_status = as.integer(P1_EMP_STATUS == "S"),
         H_emp_status = as.integer(P1_EMP_STATUS == "H"),
         U_emp_status = as.integer(P1_EMP_STATUS == "U"),
         F_emp_status = as.integer(P1_EMP_STATUS == "F"),
         V_emp_status = as.integer(P1_EMP_STATUS == "V")) %>%
  select(-P1_EMP_STATUS)
```

```{r, include = FALSE}
unique(final_dataset$P1_MAR_STATUS)
```

```{r, include = FALSE}
# Create a vector of values to exclude
excluded_values <- c("A", "C", "B", "O")

# Delete rows with excluded values
final_dataset <- final_dataset[!(final_dataset$P1_MAR_STATUS %in% excluded_values), ]
```

```{r, include = FALSE}
library(dplyr)
library(tidyr)

final_dataset <- final_dataset %>%
  mutate(P1_MAR_STATUS = factor(P1_MAR_STATUS, levels = c("M", "D", "P", "S", "W", "N"))) %>%
  mutate(P1_MAR_STATUS = as.character(P1_MAR_STATUS)) %>%
  mutate_all(~ifelse(is.na(.), "Unknown", .)) # Replace any NA values with "Unknown"

final_dataset <- final_dataset %>%
  mutate(M_Mar_status = as.integer(P1_MAR_STATUS == "M"),
         D_Mar_status = as.integer(P1_MAR_STATUS == "D"),
         P_Mar_status = as.integer(P1_MAR_STATUS == "P"),
         S_Mar_status = as.integer(P1_MAR_STATUS == "S"),
         W_Mar_status = as.integer(P1_MAR_STATUS == "W"),
         N_Mar_status = as.integer(P1_MAR_STATUS == "N")) %>%
  select(-P1_MAR_STATUS)
```

```{r, include = FALSE}
library(dplyr)
library(tidyr)

final_dataset <- final_dataset %>%
  mutate(OCC_STATUS = factor(OCC_STATUS, levels = c("PH", "UN", "LP", "HH", "WD", "WE", "OT"))) %>%
  mutate(OCC_STATUS = as.character(OCC_STATUS)) %>%
  mutate_all(~ifelse(is.na(.), "Unknown", .)) # Replace any NA values with "Unknown"

final_dataset <- final_dataset %>%
  mutate(PH_occ_status = as.integer(OCC_STATUS == "PH"),
         UN_occ_status = as.integer(OCC_STATUS == "UN"),
         LP_occ_status = as.integer(OCC_STATUS == "LP"),
         HH_occ_status = as.integer(OCC_STATUS == "HH"),
         WD_occ_status = as.integer(OCC_STATUS == "WD"),
         WE_occ_status = as.integer(OCC_STATUS == "WE"),
         OT_occ_status = as.integer(OCC_STATUS == "OT")) %>%
  select(-OCC_STATUS)
```


```{r, include = FALSE}
library(dplyr)
library(tidyr)

final_dataset <- final_dataset %>%
  mutate(POL_STATUS = factor(POL_STATUS, levels = c("Live", "Cancelled", "Lapsed", "Unknown"))) %>%
  mutate(POL_STATUS = as.character(POL_STATUS)) %>%
  mutate_all(~ifelse(is.na(.), "Unknown", .)) # Replace any NA values with "Unknown"

final_dataset <- final_dataset %>%
  mutate(Live_Pol_status = as.integer(POL_STATUS == "Live"),
         Cancelled_Pol_status = as.integer(POL_STATUS == "Cancelled"),
         Lapsed_Pol_status = as.integer(POL_STATUS == "Lapsed"),
         Unknown_Pol_status = as.integer(POL_STATUS == "Unknown")) %>%
  select(-POL_STATUS)
```


```{r, include = FALSE}

library(tagi)
# Package loading:
require(mvtnorm)
require(randtoolbox)

# #set seed
set.seed(123)

# Specific Initialization
# Define the neural network properties, such as the number of epochs, activation function, etc.
nobs <- nrow(final_dataset)
ratio <- 0.9
# Input features
x <- final_dataset[,!(names(data) %in% c("AVGsalary"))]
# Output targets
# Assuming 'data' is your dataset with the AvgSalary column
y <- as.matrix(final_dataset$AVGsalary)
nx <- ncol(x)
ny <- 1

x <- sapply(x, as.numeric)
library(dplyr)

```

```{r, include = FALSE}

NN <- list(
  "nx" = nx, # Number of input covariates
  "ny" = ny, # Number of output responses
  "batchSizeList" = c(1, 1, 1), # Batch size [train, val, test]
  "nodes" = c(nx, 30, ny), # Number of nodes for each layer
  "sx" = NULL, # Input standard deviation
  "sv" = 0.32, # Observations standard deviation
  "maxEpoch" = 10, # maximal number of learning epoch
  "hiddenLayerActivation" = "relu", # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
  "outputActivation" = "linear", # Activation function for hidden layer {'linear', 'tanh','sigm','cdf','relu'}
  "ratio" = 0.8, # Ratio between training set and validation set
  "numSplits" = 4, # Number of splits
  "task" = "regression" # Task regression or classification
)
```

```{r, include = FALSE}
# initialize weights and biases and parameters for the split between training and testing set.
# Factor for initializing bias
NN$factor4Bp = 0.01 * matrix(1L, nrow = 1, ncol = length(NN$nodes) - 1) 
# Factor for initializing weights
NN$factor4Wp = 0.25 * matrix(1L, nrow = 1, ncol = length(NN$nodes) - 1)

trainIdx <- NULL
testIdx <- NULL
```


```{r, include = FALSE}
### Experiment

# Run the neural network model and collect metrics at each epoch.
out_regression <- tagi::regression(NN, x, y, trainIdx, testIdx)
```

```{r, include = FALSE}

```

```{r, include = FALSE}

```

```{r, include = FALSE}

```

```{r, include = FALSE}

```
