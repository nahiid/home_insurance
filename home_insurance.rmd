```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, include = FALSE}
data <- read.csv("./data/home_insurance.csv")
```

##Removing Columns from the original dataset:

```{r, include = FALSE}
original_dataset <- read.csv("./data/home_insurance.csv")

#Identify the columns to remove
columns_to_remove <- c("QUOTE_DATE", "COVER_START", "P1_PT_EMP_STATUS", "CLERICAL", "AD_BUILDINGS", "AD_CONTENTS", 
"AD_CONTENTS", "RISK_RATED_AREA_C", "SUM_INSURED_CONTENTS", "CONTENTS_COVER", "P1_POLICY_REFUSED", "LISTED", "OWNERSHIP_TYPE", "PAYING_GUESTS", "PROP_TYPE", "CAMPAIGN_DESC", "PAYMENT_METHOD", "PAYMENT_FREQUENCY", "LEGAL_ADDON_PRE_REN", "LEGAL_ADDON_POST_REN", "HOME_EM_ADDON_PRE_REN", "HOME_EM_ADDON_POST_REN", "KEYCARE_ADDON_PRE_REN", "KEYCARE_ADDON_POST_REN", "HP1_ADDON_PRE_REN", "HP1_ADDON_POST_REN", "HP2_ADDON_PRE_REN", "HP2_ADDON_POST_REN", "HP3_ADDON_PRE_REN", "HP3_ADDON_POST_REN", "MTA_FLAG", "MTA_FAP", "MTA_APRP", "MTA_DATE",   "PAYING_GUESTS")

#Remove the specified columns
dataset <- original_dataset[, !(names(original_dataset) %in% columns_to_remove)]

# Step 4: Save the updated dataset to a new file
# write.csv(dataset, "./data/updated_data.csv", row.names = FALSE)
```

##Creates dataset_clean by removing rows with missing values from the original dataset.
```{r, include = FALSE}
dataset_clean <- dataset[complete.cases(dataset),]
write.csv(dataset_clean, "./data/clean_data.csv", row.names = FALSE)
```

##Read clean dataset.
```{r, include = FALSE}
dataset_clean <- read.csv("./data/clean_data.csv")
unique(dataset_clean$P1_DOB)
```

## convert the Date of birth column to Year of birth.
```{r, include = FALSE}
#Change format of DOB
# Load the lubridate package
library(lubridate)

# Convert the date column to a Date object
dataset_clean$P1_DOB <- dmy(dataset_clean$P1_DOB)  # Assumes day-month-year format

unique(dataset_clean$P1_DOB)

# Extract the year from the date column
dataset_clean$year <- year(dataset_clean$P1_DOB)

# Print the data frame with the extracted year
unique(dataset_clean$year)
```

##Reanming Columns
```{r, include = FALSE}
# Define the new column names
new_column_names <- c(
  "Claim_3_Years", "Employment_Status", "Business_Use", "Risk_Rated_Area_B",
  "Sum_Insured_Buildings", "NCD_Granted_Years_B", "NCD_Granted_Years_C",
  "Buildings_Cover", "Spec_Sum_Insured", "Spec_Item_Premium", "Unspec_HRP_Premium",
  "Date_of_Birth", "Marital_Status", "Sex", "Approved_Alarm", "Approved_Locks",
  "Bedrooms", "Roof_Construction", "Wall_Construction", "Flood_Risk",
  "Max_Days_Unoccupied", "Neighborhood_Watch", "Occupation_Status", "Security_Installed",
  "Security_Discount_Required", "Subsidence_Risk", "Year_Built", "Garden_Addon_Pre_Renovation",
  "Garden_Addon_Post_Renovation", "Last_Annual_Premium_Gross", "Policy_Status",
  "Record_ID", "Police_Station", "Year_of_Birth"
)

# Rename the columns
colnames(dataset_clean) <- new_column_names

# Check the updated column names
names(dataset_clean)

```

##Add age for each client
```{r, include = FALSE}
# Calculate the age for each client as of 2000
current_year <- 2007
dataset_clean$Age <- current_year - dataset_clean$Year_of_Birth

# Remove the "Year_of_Birth" column
dataset_clean <- subset(dataset_clean, select = -c(Year_of_Birth))

# check the updated dataset
head(dataset_clean)  # View the first few rows to verify the changes.
```


##Remove rows which include meaningless values
```{r, include = FALSE}
dataset_clean <- dataset_clean[!(dataset_clean$Employment_Status %in% c("A", "C", "I", "N")), ]
```


##Check the chosen columns unique values for estimating Salary.
```{r, include = FALSE}
# Print the sorted numbers
sort(unique(dataset_clean$Age))
unique(dataset_clean$Bedrooms)
unique(dataset_clean$Employment_Status)
unique(dataset_clean$Occupation_Status)
unique(dataset_clean$Garden_Addon_Pre_Renovation)
unique(dataset_clean$Business_Use)
```


##Add approximate salary
```{r, include = FALSE}
# Define Rating Scales
age_ratings <- c(2, 3, 4, 5, 4, 3)
emp_status_ratings <- c(1, 5, 4, 4, 1, 1, 1)
bus_use_ratings <- c(1, 3)
bedroom_ratings <- c(1, 2, 3, 4, 5, 4, 3)
garden_add_ratings <- c(1, 2)
occ_status_ratings <- c(4, 3)

# Function to calculate the total rate for each client
calculate_total_rate <- function(age, emp_status, bus_use, bedrooms, garden_add, occ_status) {
  age_rate <- age_ratings[findInterval(age, c(20, 31, 41, 51, 61, 71, Inf))]
  emp_status_rate <- emp_status_ratings[match(emp_status, c("R", "E", "S", "F", "H", "U", "V"))]
  bus_use_rate <- bus_use_ratings[match(bus_use, c("N", "Y"))]
  bedroom_rate <- bedroom_ratings[match(bedrooms, c(1, 2, 3, 4, 5, 6, 7))]
  garden_add_rate <- garden_add_ratings[match(garden_add, c("N", "Y"))]
  occ_status_rate <- occ_status_ratings[match(occ_status, c("PH", "UN", "LP", "HH", "WD", "WE", "OT"))]
  
  total_rate <- age_rate + emp_status_rate + bus_use_rate + bedroom_rate + garden_add_rate + occ_status_rate
  return(total_rate)
}

dataset_clean$Approx_Salary <- calculate_total_rate(dataset_clean$Age,
                                                    dataset_clean$Employment_Status,
                                                    dataset_clean$Business_Use,
                                                    dataset_clean$Bedrooms,
                                                    dataset_clean$Garden_Addon_Pre_Renovation,
                                                    dataset_clean$Occupation_Status)

# Convert the Approx_Salary_Rate column to numeric
dataset_clean$Approx_Salary <- as.numeric(dataset_clean$Approx_Salary)


# Define mapping of total rate to approximate annual salary in thousands (K)
salary_ranges <- cut(dataset_clean$Approx_Salary,
                     breaks = c(0, 8, 12, 16, 20, Inf),
                     labels = c("Less than 8K", "8K - 12K", "12K - 16K", "16K - 20K", "More than 20K"))

# Add the salary range column to the dataframe
dataset_clean$Approx_Salary_Annual_K <- salary_ranges

# Print the resulting dataframe with the approximate salary and salary range
print(dataset_clean)

```
##UP TO HERE####################################


```{r, include = FALSE}
final_dataset <- dataset_clean[, !(colnames(dataset_clean) %in% "P1_DOB")]
final_dataset <- dataset_clean[, !(colnames(dataset_clean) %in% "Police")]
write.csv(final_dataset, "./data/final_dataset.csv", row.names = FALSE)
```

```{r, include = FALSE}
final_dataset <- read.csv("./data/final_dataset.csv")
```

```{r, include = FALSE}
# Specify the column names that need to be changed
columns_to_change <- c("CLAIM3YEARS", "BUS_USE", "BUILDINGS_COVER", "APPR_LOCKS", "APPR_ALARM", "FLOODING", "NEIGH_WATCH", "SAFE_INSTALLED", "SEC_DISC_REQ", "SUBSIDENCE", "GARDEN_ADDON_PRE_REN", "GARDEN_ADDON_POST_REN")  

#  replace 'Y' with 1 and 'N' with 0
for (col in columns_to_change) {
  final_dataset[, col] <- ifelse(final_dataset[, col] == 'Y', 1, 0)
}
final_dataset$P1_SEX <- ifelse(final_dataset$P1_SEX == 'M', 0, 1)
```

```{r, include = FALSE}
# Assuming you're using the dplyr library
library(dplyr)

# Remove the 'p1DOB' column from the 'final_dataset' dataframe
final_dataset <- final_dataset %>% select(-'P1_DOB')

final_dataset <- final_dataset[!(final_dataset$P1_EMP_STATUS %in% c("A", "C", "I", "N")), ]

```

```{r, include = FALSE}
 unique(final_dataset$P1_EMP_STATUS)
```

```{r, include = FALSE}
 library(dplyr)
library(tidyr)

final_dataset <- final_dataset %>%
  mutate(P1_EMP_STATUS = factor(P1_EMP_STATUS, levels = c("R", "E", "S", "H", "U", "F", "V"))) %>%
  mutate(P1_EMP_STATUS = as.character(P1_EMP_STATUS)) %>%
  mutate_all(~ifelse(is.na(.), "Unknown", .)) # Replace any NA values with "Unknown"

final_dataset <- final_dataset %>%
  mutate(R_emp_status = as.integer(P1_EMP_STATUS == "R"),
         E_emp_status = as.integer(P1_EMP_STATUS == "E"),
         S_emp_status = as.integer(P1_EMP_STATUS == "S"),
         H_emp_status = as.integer(P1_EMP_STATUS == "H"),
         U_emp_status = as.integer(P1_EMP_STATUS == "U"),
         F_emp_status = as.integer(P1_EMP_STATUS == "F"),
         V_emp_status = as.integer(P1_EMP_STATUS == "V")) %>%
  select(-P1_EMP_STATUS)
```

```{r, include = FALSE}
unique(final_dataset$P1_MAR_STATUS)
```

```{r, include = FALSE}
# Create a vector of values to exclude
excluded_values <- c("A", "C", "B", "O")

# Delete rows with excluded values
final_dataset <- final_dataset[!(final_dataset$P1_MAR_STATUS %in% excluded_values), ]
```

```{r, include = FALSE}
library(dplyr)
library(tidyr)

final_dataset <- final_dataset %>%
  mutate(P1_MAR_STATUS = factor(P1_MAR_STATUS, levels = c("M", "D", "P", "S", "W", "N"))) %>%
  mutate(P1_MAR_STATUS = as.character(P1_MAR_STATUS)) %>%
  mutate_all(~ifelse(is.na(.), "Unknown", .)) # Replace any NA values with "Unknown"

final_dataset <- final_dataset %>%
  mutate(M_Mar_status = as.integer(P1_MAR_STATUS == "M"),
         D_Mar_status = as.integer(P1_MAR_STATUS == "D"),
         P_Mar_status = as.integer(P1_MAR_STATUS == "P"),
         S_Mar_status = as.integer(P1_MAR_STATUS == "S"),
         W_Mar_status = as.integer(P1_MAR_STATUS == "W"),
         N_Mar_status = as.integer(P1_MAR_STATUS == "N")) %>%
  select(-P1_MAR_STATUS)
```

```{r, include = FALSE}
library(dplyr)
library(tidyr)

final_dataset <- final_dataset %>%
  mutate(OCC_STATUS = factor(OCC_STATUS, levels = c("PH", "UN", "LP", "HH", "WD", "WE", "OT"))) %>%
  mutate(OCC_STATUS = as.character(OCC_STATUS)) %>%
  mutate_all(~ifelse(is.na(.), "Unknown", .)) # Replace any NA values with "Unknown"

final_dataset <- final_dataset %>%
  mutate(PH_occ_status = as.integer(OCC_STATUS == "PH"),
         UN_occ_status = as.integer(OCC_STATUS == "UN"),
         LP_occ_status = as.integer(OCC_STATUS == "LP"),
         HH_occ_status = as.integer(OCC_STATUS == "HH"),
         WD_occ_status = as.integer(OCC_STATUS == "WD"),
         WE_occ_status = as.integer(OCC_STATUS == "WE"),
         OT_occ_status = as.integer(OCC_STATUS == "OT")) %>%
  select(-OCC_STATUS)
```


```{r, include = FALSE}
library(dplyr)
library(tidyr)

final_dataset <- final_dataset %>%
  mutate(POL_STATUS = factor(POL_STATUS, levels = c("Live", "Cancelled", "Lapsed", "Unknown"))) %>%
  mutate(POL_STATUS = as.character(POL_STATUS)) %>%
  mutate_all(~ifelse(is.na(.), "Unknown", .)) # Replace any NA values with "Unknown"

final_dataset <- final_dataset %>%
  mutate(Live_Pol_status = as.integer(POL_STATUS == "Live"),
         Cancelled_Pol_status = as.integer(POL_STATUS == "Cancelled"),
         Lapsed_Pol_status = as.integer(POL_STATUS == "Lapsed"),
         Unknown_Pol_status = as.integer(POL_STATUS == "Unknown")) %>%
  select(-POL_STATUS)
```


```{r, include = FALSE}

library(tagi)
# Package loading:
require(mvtnorm)
require(randtoolbox)

# #set seed
set.seed(123)

# Specific Initialization
# Define the neural network properties, such as the number of epochs, activation function, etc.
nobs <- nrow(final_dataset)
ratio <- 0.9
# Input features
x <- final_dataset[,!(names(data) %in% c("AVGsalary"))]
# Output targets
# Assuming 'data' is your dataset with the AvgSalary column
y <- as.matrix(final_dataset$AVGsalary)
nx <- ncol(x)
ny <- 1

x <- sapply(x, as.numeric)
library(dplyr)

```

```{r, include = FALSE}

NN <- list(
  "nx" = nx, # Number of input covariates
  "ny" = ny, # Number of output responses
  "batchSizeList" = c(1, 1, 1), # Batch size [train, val, test]
  "nodes" = c(nx, 30, ny), # Number of nodes for each layer
  "sx" = NULL, # Input standard deviation
  "sv" = 0.32, # Observations standard deviation
  "maxEpoch" = 10, # maximal number of learning epoch
  "hiddenLayerActivation" = "relu", # Activation function for hidden layer {'tanh','sigm','cdf','relu','softplus'}
  "outputActivation" = "linear", # Activation function for hidden layer {'linear', 'tanh','sigm','cdf','relu'}
  "ratio" = 0.8, # Ratio between training set and validation set
  "numSplits" = 4, # Number of splits
  "task" = "regression" # Task regression or classification
)
```

```{r, include = FALSE}
# initialize weights and biases and parameters for the split between training and testing set.
# Factor for initializing bias
NN$factor4Bp = 0.01 * matrix(1L, nrow = 1, ncol = length(NN$nodes) - 1) 
# Factor for initializing weights
NN$factor4Wp = 0.25 * matrix(1L, nrow = 1, ncol = length(NN$nodes) - 1)

trainIdx <- NULL
testIdx <- NULL
```


```{r, include = FALSE}
### Experiment

# Run the neural network model and collect metrics at each epoch.
out_regression <- tagi::regression(NN, x, y, trainIdx, testIdx)
```

```{r, include = FALSE}

```

```{r, include = FALSE}

```

```{r, include = FALSE}

```

```{r, include = FALSE}

```
